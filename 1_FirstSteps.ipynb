{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1213bad4-170e-402a-ae50-a30a6bb61309",
   "metadata": {},
   "source": [
    "# Using satellite data to monitor urban green space\n",
    "### Joe Fennell, 2021\n",
    "In this activity, we will look at the use of satellite data to address the United Nations' Sustainable Development Goals (SDGs) through a mixture of learning material and experimentation with real data. This will take you about 1 hour to work through.\n",
    "\n",
    "| ![Sentinel 2](images/Sentinel-2.jpg) |\n",
    "|:---:|\n",
    "|*Sentinel-2 Satellite. Image from the European Space Agency*|\n",
    "\n",
    "## 1. How to access this resource \n",
    "This learning resource is a [Jupyter Notebook](https://jupyter.org/). It brings together text, images and code, allowing us to try out techniques alongside the relevant information. I have used the [Python](https://www.python.org/) programming language to produce this but you don't need to know Python to use this resource.\n",
    "\n",
    "A Jupyter Notebook can either be used *statically* (you can only view the contents) or *dynamically* (you can run, alter, re-run and interact with the Python code within the notebook). You can do many useful things with Jupyter Notebooks and [there is a useful demonstration Notebook here](https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb) that explains the different features.\n",
    "\n",
    "If you are reading this information on the GitHub website or in another *static* format, you won't be able to use the interactive features. If you would like to interact with the experiments below, please [click this link](https://colab.research.google.com/github/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb) to open the Jupyter Notebook in Google Colaboratory. This sometimes requires you to log in to a google account but once you have created an account and logged in, it is free to use. Alternatively, you can view a static version [here](https://nbviewer.jupyter.org/github/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb)\n",
    "\n",
    "Once you have opened this activity in Google Colaboratory ([click this link](https://colab.research.google.com/github/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb)) it is important to run the entire notebook before continuing. Do this now by clicking `Runtime > Run all` in the menu above.\n",
    "\n",
    ">Note: if you double click on this cell, you will view the markdown code instead of the rendered text. Simply re-run the cell or the whole notebook (see above) to return it to the original state.\n",
    "\n",
    "![im.1](images/jlabs_run_nb.png)\n",
    "\n",
    "## 2. Learning Outcomes\n",
    "After studying this material, you should be able to:\n",
    "- Use a Jupyter Notebook learning resource to learn about new concepts\n",
    "- Recall and summarise an application of remote sensing in the UK's environmental strategy\n",
    "- Apply simple image analysis techniques to optical remote sensing data\n",
    "\n",
    "## 3. A UK Case Study: Biodiversity Net Gain\n",
    "The UK Government has recently introduced a policy called Biodiversity Net Gain. This provides a framework for building developers to prevent loss (and ideally increase) the quality and quantity of habitats alterered by construction.\n",
    "\n",
    "Natural England (a government agency) explain the concept in [this video](https://www.youtube.com/watch?v=loDGyw_jh1s).\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/loDGyw_jh1s/0.jpg)](https://www.youtube.com/watch?v=loDGyw_jh1s)\n",
    "\n",
    "**Question: Which of the UN Sustainable Development subgoals could be achieved through a policy such as this?** Make a note of all that you think apply before checking the suggestions below. Hint: [UN SDG Website](https://www.globalgoals.org/) \n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "Show answers\n",
    "</summary>\n",
    "\n",
    "|    |Life on Land| | Sustainable Cities|\n",
    "|:---|:---|:---|:---|\n",
    "| ![SDG15.1](https://images.prismic.io/globalgoals%2F5d08ea5a-c0b5-49a4-993d-40bd2f3d46f9_goal_15.1_rgb_ng.svg?auto=compress,format) | 15.1: Conserve and restore <br /> terrestrial and freshwater ecosystems | ![SDG11.6](https://images.prismic.io/globalgoals%2Fe2c7c5dc-973d-48d4-aa46-606fc9e24961_goal_11.4_rgb_ng.svg?auto=compress,format) | 11.6: Reduce the environmental impact of cities |\n",
    "| ![SDG15.5](https://images.prismic.io/globalgoals%2F5d08ea5a-c0b5-49a4-993d-40bd2f3d46f9_goal_15.1_rgb_ng.svg?auto=compress,format) | 15.5 Protect Biodiversity <br /> and Natural Habitats  | ![SDG11.7](https://images.prismic.io/globalgoals%2Fa734a3ab-0cb8-4252-8479-318b3446a0c3_goal_11.7_rgb_ng.svg?auto=compress,format) | 11.7: Provide access to safe and inclusive green and public spaces |\n",
    "| ![SDG15.9](https://images.prismic.io/globalgoals%2F4873dc0f-0980-46f0-8186-a4a6b3d9e693_goal_15.9_rgb_ng.svg?auto=compress,format) | 15.9: Integrate Ecosystem <br />and Biodiversity in government planning | | |\n",
    "\n",
    ">Although, as is often the case, many of the SDGs may apply indirectly to biodiversity protection and habitat restoration, these are the most relevant to the policy.\n",
    "<p>&nbsp;</p>\n",
    "</details>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Whilst the policy may support sustainable development, a key risk is that it requires detailed, quantified assessment of the ecosystem in order for the scheme to work. Whilst it has been argued that Biodiversity Net Gain is better than no action on biodiversity loss, observers have noted that\n",
    "\n",
    "> \"Outsourcing of the delivery of environmental goods through a mix of regulation and incentive is not adequately resourced to ensure regulatory authorities are able to monitor the process.\"\n",
    "> <cite>[(Knight-Lenihan, 2020)][1]</cite>\n",
    "\n",
    "[1]: https://rdcu.be/cyob0\n",
    "\n",
    "Both the initial assessment for a planning application, and compliance monitoring by government agencies, is labour-intensive, expensive and potentially open to corruption. Because of this, there is considerable interest in the use of **Remote Sensing** to automate some parts of the process. In the rest of this activity, we will look at the use of a specific remote sensing technique to identify different habitat types in an urban area.\n",
    "\n",
    "## 4. An Introduction to Remote Sensing\n",
    "One of the key challenges in environmental science is measuring the properties of the Earth's surface in order to understand the processes that shape it. However, even in accessible areas, carrying out this work on the ground has always been expensive and difficult. One solution is to measure properties of the surface remotely with a sensor or array of sensors. This is **Remote Sensing**.\n",
    "\n",
    "There are many different types of sensing technology but we will focus on optical imaging. A camera, such as the one on your phone, is an example of an optical imaging system. A camera collects light through a lens and projects it onto an imaging sensor. The sensor collects the lights in each pixel and converts this into an electrical signal. This is read by the camera electronics and converted into values (sometimes referred to as Digital Number values) proportional to the amount of light collected by each pixel.\n",
    "\n",
    "Just like human eyes, most camera sensors are designed to measure not only the overall brightness, but the brightness of specific wavebands. A colour camera measures red, green and blue light independently. Some systems measure more colours or colours in different parts of the electromagnetic spectrum. We normally refer to these as multispectral or hyperspectral systems.\n",
    "\n",
    "Cameras can be mounted on various craft including Unmanned Aerial Vehicles (UAVs), planes and satellites. One particularly useful earth observation system is The European Space Agency's Sentinel 2 constellation.\n",
    "\n",
    "| ![Sentinel 2](images/Sentinel-2.jpg) |\n",
    "|:---:|\n",
    "| *An artists impression of one of the Sentinel-2 satellites in an imaging orbit. Image from the European Space Agency* |\n",
    "\n",
    "The pair of Sentinel 2 satellites constantly orbit the earth in a sun-synchronous orbit (following the daylight), allowing the constellation to capture an image of the same point on the earth every 6 days. The imagery is processed automatically and made available to everyone for free.\n",
    "\n",
    "We will use Python to load in some example Sentinel 2 imagery of London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d8dea1-1d67-4d31-9780-822da87598ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell, it contains instructions in the Python coding language.\n",
    "# The grey area is the code input area and the white area below displays the outputs.\n",
    "# The cell can be re-run by pressing shift-enter\n",
    "# -----------------------------------------------\n",
    "# Boiler plate imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Some google colaboratory specific instructions\n",
    "\n",
    "dpath = 'eo-for-sdgs/data/S2_London.npy'\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    !git clone https://github.com/joe-fennell/eo-for-sdgs/\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    dpath = 'data/S2_London.npy'\n",
    "\n",
    "# A function for doing image histogram equalisation\n",
    "def image_histogram_equalisation(image):\n",
    "    \"\"\" Performs an image histogram equalisation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array-like\n",
    "        image must have 3 dimensions with band in the 3rd dimension\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_corrected : array\n",
    "        equalised image of same shape as input\n",
    "    \n",
    "    \"\"\"\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), 256, normed=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = (255-1) * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')[:,:,::-1]\n",
    "    else:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580ae139-2641-4e70-aa70-00e7e2268e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the pixel size a priori. We know this is 10m x 10m for these data\n",
    "pixel_size = 10\n",
    "\n",
    "# Read in the dataset and convert to float type\n",
    "im = np.load(dpath).astype(float)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ec1f6-96a5-4e39-aeb6-8a1473805eed",
   "metadata": {},
   "source": [
    "We can inspect the shape of the new object we created (called `im1`) by calling the `shape` method. This gives an output indicating the array is 1000 x 1000 pixels in the spatial dimensions and has 4 colour channels.\n",
    "\n",
    "**Question: What ground area does our image cover if each pixel is 10m x 10m?**\n",
    "<details>\n",
    "<summary>\n",
    "Show answers\n",
    "</summary>\n",
    "\n",
    "\n",
    "> First calculate the length in metres of each dimension by multiplying the pixel size (10m) by the number of pixels (1000): $10 \\times 1000 = 10,000$, then multiply the two together to get the area: $10,000 \\times 10,000= 100,000,000$m$^{2}$ or $1$km$^{2}$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "</details>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305166fb-889c-41eb-b4ef-ade4adad7ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c8b77c2df24dd7989c38e03df44e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Delayed'), IntText(value=0, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "a = widgets.IntSlider(description=\"Delayed\", continuous_update=False)\n",
    "b = widgets.IntText(description=\"Delayed\", continuous_update=False)\n",
    "c = widgets.IntSlider(description=\"Continuous\", continuous_update=True)\n",
    "d = widgets.IntText(description=\"Continuous\", continuous_update=True)\n",
    "\n",
    "widgets.link((a, 'value'), (b, 'value'))\n",
    "widgets.link((a, 'value'), (c, 'value'))\n",
    "widgets.link((a, 'value'), (d, 'value'))\n",
    "widg = widgets.VBox([a,b,c,d])\n",
    "\n",
    "display(widg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "099d4cfb028145f88d18c9363cc198c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ac33b51efc34eb4babd7e22f2e47f27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ace485055a14f0b91cc1de846bdcd18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4135d50403704353a3967ac5d1d507c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "59c09774d18544939bfe1f084828e665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "66c7e448b2ae447ebcabb1a18906d1f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6a5104c5a97f43ee8be14b64a899b044": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7ea3215414104c3a81b5054f16884f91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Delayed",
       "layout": "IPY_MODEL_1ac33b51efc34eb4babd7e22f2e47f27",
       "step": 1,
       "style": "IPY_MODEL_59c09774d18544939bfe1f084828e665"
      }
     },
     "a25b521935f24a8e90df9b525ecc6929": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d442030c623c4b50bfa38ac7bab97f6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "Continuous",
       "layout": "IPY_MODEL_099d4cfb028145f88d18c9363cc198c0",
       "style": "IPY_MODEL_66c7e448b2ae447ebcabb1a18906d1f4"
      }
     },
     "e0c8b77c2df24dd7989c38e03df44e65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fc653ba3382d4164b4b61758aafe881c",
        "IPY_MODEL_7ea3215414104c3a81b5054f16884f91",
        "IPY_MODEL_d442030c623c4b50bfa38ac7bab97f6d",
        "IPY_MODEL_f640658ae9d84f32bf31640c9b56e191"
       ],
       "layout": "IPY_MODEL_1ace485055a14f0b91cc1de846bdcd18"
      }
     },
     "f640658ae9d84f32bf31640c9b56e191": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "continuous_update": true,
       "description": "Continuous",
       "layout": "IPY_MODEL_6a5104c5a97f43ee8be14b64a899b044",
       "step": 1,
       "style": "IPY_MODEL_fa76c7e4a8174b139cd8fffda6dc85b0"
      }
     },
     "fa76c7e4a8174b139cd8fffda6dc85b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fc653ba3382d4164b4b61758aafe881c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "continuous_update": false,
       "description": "Delayed",
       "layout": "IPY_MODEL_4135d50403704353a3967ac5d1d507c2",
       "style": "IPY_MODEL_a25b521935f24a8e90df9b525ecc6929"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
