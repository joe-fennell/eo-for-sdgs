{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1213bad4-170e-402a-ae50-a30a6bb61309",
   "metadata": {},
   "source": [
    "# Using satellite data to monitor urban green space\n",
    "### Joe Fennell, 2021\n",
    "![Sentinel 2](images/Sentinel-2.jpg)\n",
    "\n",
    "In this activity, we will look at the use of satellite data to address United Nations Sustainable Development Goals through a mixture of learning material and experimentation with real data. This will take you about 1 hour to work through.\n",
    "\n",
    "## 1. How to access this resource \n",
    "This learning resource is a [Jupyter Notebook](https://jupyter.org/). It brings together text, images and code, allowing us to try out techniques alongside the relevant information. I have used the [Python](https://www.python.org/) programming language to produce this but you don't need to know Python to use this resource.\n",
    "\n",
    "A Jupyter Notebook can either be used *statically* (you can only view the contents) or *dynamically* (you can run, alter, re-run and interact with the Python code within the notebook). You can do many useful things with Jupyter Notebooks and [there is a useful demonstration Notebook here](https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb) that explains the different features.\n",
    "\n",
    "If you are reading this information on the GitHub website or in another *static* format, you won't be able to use the interactive features. If you would like to interact with the experiments below, please [click this link](https://colab.research.google.com/github/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb) to open the Jupyter Notebook in Google Colaboratory. This sometimes requires you to log in to a google account but once you have created an account and logged in, it is free to use. Alternatively, you can view a static version [here](https://github.com/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb)\n",
    "\n",
    "Once you have opened this activity in Google Colaboratory ([click this link](https://colab.research.google.com/github/joe-fennell/eo-for-sdgs/blob/main/1_FirstSteps.ipynb)) it is important to run the entire notebook before continuing. Do this now by clicking `Runtime > Run all` in the menu above.\n",
    "\n",
    ">Note: if you double click on this cell, you will view the markdown code instead of the rendered text. Simply re-run the cell or the whole notebook (see above) to return it to the original state.\n",
    "\n",
    "![im.1](images/jlabs_run_nb.png)\n",
    "\n",
    "## 2. Learning Outcomes\n",
    "After studying this material, you should be able to:\n",
    "- Recall and summarise an application of remote sensing in the UK's environmental strategy\n",
    "- Apply simple image analysis techniques to optical remote sensing data\n",
    "\n",
    "## 3. Biodiversity Net Gain\n",
    "The UK Government has recently introduced a policy called Biodiversity Net Gain (BNG). This provides a framework for building developers to prevent loss (and ideally increase) the quality and quantity of habitats alterered by construction.\n",
    "\n",
    "Their concept is explained in [this video](https://www.youtube.com/watch?v=loDGyw_jh1s) from Natural England (a government agency).\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/loDGyw_jh1s/0.jpg)](https://www.youtube.com/watch?v=loDGyw_jh1s)\n",
    "\n",
    "**Question: Which of the UN Sustainable Development subgoals could be achieved through a policy such as this?** Make a note of all that you think apply before checking the suggestions below. Hint: [UN SDG Website](https://www.globalgoals.org/) \n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "Show answers:\n",
    "</summary>\n",
    "\n",
    "|    |Life on Land| | Sustainable Cities|\n",
    "|:---|:---|:---|:---|\n",
    "| ![SDG15.1](https://images.prismic.io/globalgoals%2F5d08ea5a-c0b5-49a4-993d-40bd2f3d46f9_goal_15.1_rgb_ng.svg?auto=compress,format) | 15.1: Conserve and restore <br /> terrestrial and freshwater ecosystems | ![SDG11.6](https://images.prismic.io/globalgoals%2Fe2c7c5dc-973d-48d4-aa46-606fc9e24961_goal_11.4_rgb_ng.svg?auto=compress,format) | 11.6: Reduce the environmental impact of cities |\n",
    "| ![SDG15.5](https://images.prismic.io/globalgoals%2F5d08ea5a-c0b5-49a4-993d-40bd2f3d46f9_goal_15.1_rgb_ng.svg?auto=compress,format) | 15.5 Protect Biodiversity <br /> and Natural Habitats  | ![SDG11.7](https://images.prismic.io/globalgoals%2Fa734a3ab-0cb8-4252-8479-318b3446a0c3_goal_11.7_rgb_ng.svg?auto=compress,format) | 11.7: Provide access to safe and inclusive green and public spaces |\n",
    "| ![SDG15.9](https://images.prismic.io/globalgoals%2F4873dc0f-0980-46f0-8186-a4a6b3d9e693_goal_15.9_rgb_ng.svg?auto=compress,format) | 15.9: Integrate Ecosystem <br />and Biodiversity in government planning | | |\n",
    "\n",
    ">Although, as is often the case, many of the SDGs may apply indirectly to biodiversity protection and habitat restoration, these are the most relevant to the policy.\n",
    "<p>&nbsp;</p>\n",
    "</details>\n",
    "<p>&nbsp;</p>\n",
    "A key issue with this approach is that it requires detailed, quantified assessment of the ecosystem. In fact, as the scheme is so new, there is little understanding of the potential risks. Whilst it has been argued that BNG is better than no action on biodiversity loss, observers have noted that\n",
    "\n",
    "> \"Outsourcing of the delivery of environmental goods through a mix of regulation and incentive is not adequately resourced to ensure regulatory authorities are able to monitor the process.\"\n",
    "> <cite>[(Knight-Lenihan, 2020)][1]</cite>\n",
    "\n",
    "[1]: https://rdcu.be/cyob0\n",
    "\n",
    "Both the initial assessment for a planning application, and compliance monitoring by government agencies, is labour-intensive, expensive and potentially open to corruption. Because of this, there is considerable interest in the use of **Remote Sensing** to automate some parts of the process. In the rest of this activity, we will look at the use of a specific remote sensing technique to identify different habitat types in an urban area.\n",
    "\n",
    "## 4. An Introduction to Remote Sensing\n",
    "One of the key challenges in environmental science is measuring the properties of the Earth's surface in order to understand the processes that shape it. However, even in accessible areas, carrying out this work on the ground has always been expensive and difficult. One solution is to measure properties of the surface remotely with a sensor or array of sensors. This is **Remote Sensing**.\n",
    "\n",
    "### 4.1 Basics of Imaging\n",
    "Whilst there are many different types of sensing technology, we will focus on the use of optical imaging. A camera, such as the one on your phone, is an example of an optical imaging system. It is a passive system that collects light through a lens and projects it onto an **imaging sensor**. The sensor collects the lights in each **pixel** and converts this into an electrical signal. This is read by the camera electronics and converted into values proportional to the magnitude ('brightness') of the light collected by each pixel.\n",
    "\n",
    "Just like human eyes, most camera sensors are designed to measure not only the overall brightness, but the brightness of red, green and blue light independently. Some systems can measure more colours. We call these multispectral or hyperspectral systems.\n",
    "\n",
    "Cameras can be mounted on different **platforms** including Unmanned Aerial Vehicles (UAVs), planes and other vehicles, but we will focus on a specific satellite system: The European Space Agency's Sentinel 2 constellation.\n",
    "\n",
    "| ![Sentinel 2](images/Sentinel-2.jpg) |\n",
    "|:---:|\n",
    "| *An artists impression of one of the Sentinel-2 satellites in an imaging orbit* |\n",
    "\n",
    "The pair of Sentinel 2 satellites constantly orbit the earth in a sun-synchronous orbit (following the daylight), allowing the constellation to capture an image of the same patch on the earth every 6 days. We will look at some of that data here. We will use Python to load in some preprocessed Sentinel 2 imagery of London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d8dea1-1d67-4d31-9780-822da87598ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell, it contains instructions in the Python coding language.\n",
    "# The grey area is the code input area and the white area below displays the outputs.\n",
    "# The cell can be re-run by pressing shift-enter\n",
    "# -----------------------------------------------\n",
    "# Boiler plate imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Some google colab specific stuff\n",
    "try:\n",
    "    from google.colab import files\n",
    "    !git clone https://github.com/joe-fennell/eo-for-sdgs/\n",
    "    dpath = 'eo-for-sdgs/data/S2_London.npy'\n",
    "except:\n",
    "    dpath = 'data/S2_London.npy'\n",
    "\n",
    "# A function for doing image histogram equalisation\n",
    "def image_histogram_equalisation(image):\n",
    "    \"\"\" Performs an image histogram equalisation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array-like\n",
    "        image must have 3 dimensions with band in the 3rd dimension\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_corrected : array\n",
    "        equalised image of same shape as input\n",
    "    \n",
    "    \"\"\"\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), 256, normed=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = (255-1) * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')[:,:,::-1]\n",
    "    else:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580ae139-2641-4e70-aa70-00e7e2268e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the pixel size a priori. We know this is 10m x 10m for these data\n",
    "pixel_size = 10\n",
    "\n",
    "# Read in the dataset and convert to float type\n",
    "im1 = np.load(dpath).astype(float)\n",
    "im1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ec1f6-96a5-4e39-aeb6-8a1473805eed",
   "metadata": {},
   "source": [
    "We can inspect the shape of the new object we created (called `im1`) by calling the `shape` method. This gives an output indicating the array is 1000 x 1000 pixels in the spatial dimensions and has 4 colour channels.\n",
    "\n",
    "**Question: What ground area does this represent if each pixel is 10m x 10m?**\n",
    "<details>\n",
    "<summary>\n",
    "Show answers:\n",
    "</summary>\n",
    "\n",
    "\n",
    "> First calculate the length in metres of each dimension by multiplying the pixel size by the number of pixels: $10 \\times 1000 = 10,000$, then multiply the two together to get the area: $10,000 \\times 10,000= 100,000,000$m$^{2}$ or $1$km$^{2}$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "</details>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305166fb-889c-41eb-b4ef-ade4adad7ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fb131ee2ce489c86387fdc81572dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Delayed'), IntText(value=0, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "a = widgets.IntSlider(description=\"Delayed\", continuous_update=False)\n",
    "b = widgets.IntText(description=\"Delayed\", continuous_update=False)\n",
    "c = widgets.IntSlider(description=\"Continuous\", continuous_update=True)\n",
    "d = widgets.IntText(description=\"Continuous\", continuous_update=True)\n",
    "\n",
    "widgets.link((a, 'value'), (b, 'value'))\n",
    "widgets.link((a, 'value'), (c, 'value'))\n",
    "widgets.link((a, 'value'), (d, 'value'))\n",
    "widg = widgets.VBox([a,b,c,d])\n",
    "\n",
    "display(widg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "179260c17fa74aba9aa2f1831ed18166": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "22c862a2636a427ba7bcd20f275b18b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3afd7ba1ecf54e4282254f0ec5babd3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3b8e797834464c04b10bad3f47552a45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3ba64db9dbeb4403b604461b5112ccec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5985c38c167b4eb8a3f642e99038b43d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6691bfbb4c4b40d395a455856dfcfcff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Delayed",
       "layout": "IPY_MODEL_22c862a2636a427ba7bcd20f275b18b1",
       "step": 1,
       "style": "IPY_MODEL_3afd7ba1ecf54e4282254f0ec5babd3b"
      }
     },
     "66fb131ee2ce489c86387fdc81572dab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a8764b311c2d41e798510d70dee6a218",
        "IPY_MODEL_6691bfbb4c4b40d395a455856dfcfcff",
        "IPY_MODEL_7dbe2bb33742433b871b4f8ad79a4c00",
        "IPY_MODEL_9e1433604d6c4597bf0d6ef16cedda78"
       ],
       "layout": "IPY_MODEL_5985c38c167b4eb8a3f642e99038b43d"
      }
     },
     "6cadfd43ee344bdc87e12e25530bdb35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7dbe2bb33742433b871b4f8ad79a4c00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "Continuous",
       "layout": "IPY_MODEL_3b8e797834464c04b10bad3f47552a45",
       "style": "IPY_MODEL_179260c17fa74aba9aa2f1831ed18166"
      }
     },
     "9e1433604d6c4597bf0d6ef16cedda78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "continuous_update": true,
       "description": "Continuous",
       "layout": "IPY_MODEL_3ba64db9dbeb4403b604461b5112ccec",
       "step": 1,
       "style": "IPY_MODEL_6cadfd43ee344bdc87e12e25530bdb35"
      }
     },
     "a8764b311c2d41e798510d70dee6a218": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "continuous_update": false,
       "description": "Delayed",
       "layout": "IPY_MODEL_f2cf24338e3046338aa44abbe62c8a21",
       "style": "IPY_MODEL_e0f370b08fa04d9c80a6a415f04604d7"
      }
     },
     "e0f370b08fa04d9c80a6a415f04604d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f2cf24338e3046338aa44abbe62c8a21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
